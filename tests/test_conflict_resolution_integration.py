#!/usr/bin/env python3
"""
Comprehensive Integration Test: Conflict Resolution
File: tests/test_conflict_resolution_integration.py

Tests the complete integration chain:
CLI args -> extract_enhanced_args() -> operations functions -> file_conflicts -> actual file handling
"""

import argparse
import tempfile
import sys
from pathlib import Path
from unittest.mock import patch, MagicMock

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from pdf_manipulator.cli import extract_enhanced_args
from pdf_manipulator.core.operations import extract_pages
from pdf_manipulator.core.file_conflicts import resolve_file_conflicts
from pdf_manipulator.core.exceptions import FileConflictError


def create_mock_args(**kwargs):
    """Create a mock args object for testing."""
    args = argparse.Namespace()
    
    defaults = {
        'batch': False,
        'conflicts': 'ask',
        'dedup': None,
        'separate_files': False,
        'respect_groups': False,
        'smart_names': False,
        'name_prefix': None,
        'no_timestamp': False,
        'filename_template': None,
        'timestamp': False,
        'extract_pages': '1',
        'dry_run': False,
        'preview': False
    }
    
    for key, value in defaults.items():
        setattr(args, key, value)
    
    for key, value in kwargs.items():
        setattr(args, key, value)
    
    return args


def create_test_pdf(pdf_path: Path):
    """Create a minimal test PDF file."""
    # Create a simple PDF with pypdf for testing
    from pypdf import PdfWriter
    from pypdf.generic import RectangleObject, DictionaryObject, NameObject, ArrayObject, NumberObject
    
    writer = PdfWriter()
    
    # Create a simple blank page using proper pypdf API
    page = writer.add_blank_page(width=612, height=792)
    
    # Write to file
    with open(pdf_path, 'wb') as output:
        writer.write(output)


def test_batch_mode_conversion():
    """Test that batch mode converts 'ask' to 'rename'."""
    print("Testing batch mode conflict strategy conversion...")
    
    # Test interactive mode (should keep 'ask')
    args_interactive = create_mock_args(batch=False, conflicts='ask')
    enhanced_args = extract_enhanced_args(args_interactive)
    
    if enhanced_args['conflict_strategy'] == 'ask' and enhanced_args['interactive'] == True:
        print("  ‚úì Interactive mode: 'ask' strategy preserved")
        interactive_passed = True
    else:
        print(f"  ‚úó Interactive mode failed: strategy={enhanced_args['conflict_strategy']}, interactive={enhanced_args['interactive']}")
        interactive_passed = False
    
    # Test batch mode (should convert 'ask' to 'rename')  
    args_batch = create_mock_args(batch=True, conflicts='ask')
    enhanced_args = extract_enhanced_args(args_batch)
    
    if enhanced_args['conflict_strategy'] == 'rename' and enhanced_args['interactive'] == False:
        print("  ‚úì Batch mode: 'ask' converted to 'rename'")
        batch_passed = True
    else:
        print(f"  ‚úó Batch mode failed: strategy={enhanced_args['conflict_strategy']}, interactive={enhanced_args['interactive']}")
        batch_passed = False
    
    # Test explicit overwrite in batch mode (should be preserved)
    args_batch_overwrite = create_mock_args(batch=True, conflicts='overwrite')
    enhanced_args = extract_enhanced_args(args_batch_overwrite)
    
    if enhanced_args['conflict_strategy'] == 'overwrite':
        print("  ‚úì Batch mode: explicit 'overwrite' preserved")
        explicit_passed = True
    else:
        print(f"  ‚úó Batch mode explicit overwrite failed: got {enhanced_args['conflict_strategy']}")
        explicit_passed = False
    
    return interactive_passed and batch_passed and explicit_passed


def test_operations_parameter_acceptance():
    """Test that operations functions accept conflict_strategy parameter."""
    print("Testing operations function parameter acceptance...")
    
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_path = Path(temp_dir)
        test_pdf = temp_path / "test.pdf"
        
        # Create a test PDF
        create_test_pdf(test_pdf)
        
        # Test that extract_pages accepts conflict_strategy without error
        try:
            # Use dry_run=True to avoid actual file operations
            result = extract_pages(
                pdf_path=test_pdf,
                page_range="1", 
                dry_run=True,
                conflict_strategy='rename'  # This should not cause an error
            )
            
            if result == (None, 0):  # Expected dry_run return
                print("  ‚úì extract_pages accepts conflict_strategy parameter")
                return True
            else:
                print(f"  ‚úó Unexpected return from extract_pages: {result}")
                return False
                
        except TypeError as e:
            if 'conflict_strategy' in str(e):
                print(f"  ‚úó extract_pages does not accept conflict_strategy: {e}")
                return False
            else:
                print(f"  ‚úó Other TypeError in extract_pages: {e}")
                return False
        except Exception as e:
            print(f"  ‚úó Unexpected error in extract_pages: {e}")
            return False


def test_file_conflict_detection():
    """Test that file conflicts are properly detected and resolved."""
    print("Testing file conflict detection and resolution...")
    
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_path = Path(temp_dir)
        
        # Create an existing file
        existing_file = temp_path / "existing.pdf"
        existing_file.write_text("existing content")
        
        # Test different strategies
        test_cases = [
            ('skip', None, "Skip strategy should return None"),
            ('rename', 'different_name', "Rename strategy should return different path"),
            ('overwrite', existing_file, "Overwrite strategy should return same path"),
        ]
        
        passed = 0
        total = len(test_cases)
        
        for strategy, expected_type, description in test_cases:
            try:
                result_paths, skipped_paths = resolve_file_conflicts(
                    [existing_file], strategy, interactive=False
                )
                
                if strategy == 'skip':
                    if not result_paths and skipped_paths == [existing_file]:
                        print(f"  ‚úì {description}")
                        passed += 1
                    else:
                        print(f"  ‚úó {description}: got result_paths={result_paths}, skipped={skipped_paths}")
                
                elif strategy == 'rename':
                    if result_paths and len(result_paths) == 1 and result_paths[0] != existing_file:
                        print(f"  ‚úì {description}: {result_paths[0].name}")
                        passed += 1
                    else:
                        print(f"  ‚úó {description}: got {result_paths}")
                
                elif strategy == 'overwrite':
                    if result_paths == [existing_file]:
                        print(f"  ‚úì {description}")
                        passed += 1
                    else:
                        print(f"  ‚úó {description}: got {result_paths}")
                        
            except Exception as e:
                print(f"  ‚úó {description}: Exception {type(e)}: {e}")
        
        # Test fail strategy
        try:
            result_paths, skipped_paths = resolve_file_conflicts(
                [existing_file], 'fail', interactive=False
            )
            print("  ‚úó Fail strategy should have raised exception")
        except Exception as e:
            if 'conflict' in str(e).lower():
                print("  ‚úì Fail strategy correctly raised exception")
                passed += 1
            else:
                print(f"  ‚úó Fail strategy raised wrong exception: {e}")
        
        total += 1  # Account for fail test
        
        return passed == total


def test_end_to_end_integration():
    """Test complete integration from CLI args to file operations."""
    print("Testing end-to-end integration...")
    
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_path = Path(temp_dir)
        
        # Create test PDF
        test_pdf = temp_path / "source.pdf"
        create_test_pdf(test_pdf)
        
        # Create expected output file to test conflict (match actual filename generation)
        expected_output = temp_path / "source_extracted_page1.pdf"
        expected_output.write_text("existing output")
        
        test_cases = [
            # (args_kwargs, expected_behavior, description)
            ({'conflicts': 'skip', 'batch': True}, 'skip', "Batch skip should not create new file"),
            ({'conflicts': 'rename', 'batch': True}, 'rename', "Batch rename should create renamed file"),
            ({'conflicts': 'overwrite', 'batch': True}, 'overwrite', "Batch overwrite should replace file"),
        ]
        
        passed = 0
        total = len(test_cases)
        
        for args_kwargs, expected_behavior, description in test_cases:
            # Reset the existing file
            expected_output.write_text("existing output")
            original_content = expected_output.read_text()
            
            args = create_mock_args(extract_pages="1", **args_kwargs)
            
            try:
                # Call extract_pages with arguments processed through the full chain
                enhanced_args = extract_enhanced_args(args)
                
                result = extract_pages(
                    pdf_path=test_pdf,
                    page_range=args.extract_pages,
                    dry_run=False,  # Actually perform operation
                    conflict_strategy=enhanced_args['conflict_strategy']
                )
                
                if expected_behavior == 'skip':
                    # Should return None, and original file should be unchanged
                    if result == (None, 0) and expected_output.read_text() == original_content:
                        print(f"  ‚úì {description}")
                        passed += 1
                    else:
                        print(f"  ‚úó {description}: result={result}, content changed={expected_output.read_text() != original_content}")
                
                elif expected_behavior == 'rename':
                    # Should return a renamed path, original file unchanged
                    if result[0] and result[0] != expected_output and expected_output.read_text() == original_content:
                        print(f"  ‚úì {description}: created {result[0].name}")
                        passed += 1
                    else:
                        print(f"  ‚úó {description}: result={result}, original content changed={expected_output.read_text() != original_content}")
                
                elif expected_behavior == 'overwrite':
                    # Should return original path, and file should be overwritten
                    if result[0] == expected_output and expected_output.read_text() != original_content:
                        print(f"  ‚úì {description}")
                        passed += 1
                    else:
                        print(f"  ‚úó {description}: result={result}, content unchanged={expected_output.read_text() == original_content}")
                        
            except Exception as e:
                print(f"  ‚úó {description}: Exception {type(e)}: {e}")
        
        return passed == total


def run_integration_tests():
    """Run all integration tests."""
    print("üß™ Comprehensive Conflict Resolution Integration Test")
    print("=" * 60)
    
    tests = [
        test_batch_mode_conversion,
        test_operations_parameter_acceptance, 
        test_file_conflict_detection,
        test_end_to_end_integration,
    ]
    
    total_passed = 0
    total_tests = len(tests)
    
    for test_func in tests:
        print(f"\n{test_func.__name__.replace('_', ' ').title()}:")
        try:
            if test_func():
                total_passed += 1
                print("  ‚úì PASSED")
            else:
                print("  ‚úó FAILED")
        except Exception as e:
            print(f"  ‚úó FAILED with exception: {e}")
        
    print(f"\n{'='*60}")
    print(f"Integration Test Results: {total_passed}/{total_tests} passed")
    
    if total_passed == total_tests:
        print("üéâ ALL INTEGRATION TESTS PASSED!")
        print("‚úì Conflict resolution integration is working correctly")
        print("‚úì Batch mode safety conversion works") 
        print("‚úì Operations functions properly use conflict resolution")
        print("‚úì End-to-end chain from CLI to file operations works")
        return True
    else:
        failed = total_tests - total_passed
        print(f"üí• {failed} integration test(s) failed")
        print("‚ö†Ô∏è  Review the failed tests and check the integration")
        return False


if __name__ == "__main__":
    success = run_integration_tests()
    sys.exit(0 if success else 1)


# End of file #
